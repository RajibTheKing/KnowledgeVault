### 13:07
	- start working with GPT based model, for medical NER task
- ### 13:40
	- setup a new python environment for specifically GPT solution
	- learn how to use GPT based transformer model to pre-train
	- using this one https://huggingface.co/openai-community/gpt2
- ### 13:48
	- implement training and pre-processing for GPT2
	- try to move the training device to GPU
- ### 14:18
	- training is done (it took 18 minutes for 500 annotated samples on my Computer, GPU-RTX4070ti)
	- fine tuned GPT model is stored into the disk
- ### 14:32
	- it's time to write the implementations for prediction based on unseen medical texts
- ### 15:51
	- fix starting and ending index calculation, specifically for GPT tokenizer
	- 'Ġ' character used while marking the beginning of token
	- still getting **IndexError**: list index out of range ... ERROR
- ### 18:34
	- while tokenizing german texts "gefühl" becomes "gefÃ¼hl"
	- how can we stop that?
- ### 18:48
	- problem is german characters are misdecoded and resulting strings are as follows:
	- | Character | UTF-8 Bytes | Misdecoded as Latin-1 | Resulting String |
	  |-----------|-------------|-----------------------|------------------|
	  | ä         | C3 A4       | Ã + ¤                 | Ã¤               |
	  | ö         | C3 B6       | Ã + ¶                 | Ã¶               |
	  | ü         | C3 BC       | Ã + ¼                 | Ã¼               |
	  | ß         | C3 9F       | Ã + Ÿ                 | ÃŸ               |
- ### 19:18
	- Ensure correct UTF-8 encoding while processing text
		- ```python
		  text = text.encode('utf-8').decode('utf-8')
		  ```
		- this fix doesn't work
- ### 19:53
	- try loading german language based GPT model
		- ```python
		  model_id = "dbmdz/german-gpt2
		  ```
	- this fix doesn't work
- ### 21:01
	- we will replace all german characters with their respective resulting string for whole input dataset
	- DONE we need to write a function that will do the job (forward transformation)
	- TODO we need to write a function that will do the job (backward transformation)
	- this fix doesn't work
- 22:40
	- we need think some other ways to fix this
- 23:35
	- failed every attempts
	- tried to run code snippet on google colab, output is the same, can't handle utf-8 characters
	- post the question into the stackoverflow, let's wait if someone has better solution approach
	- https://stackoverflow.com/questions/79482290/how-to-handle-german-language-specific-characters-like-%c3%a4-%c3%b6-%c3%bc-%c3%9f-while-tokeni
	-
	-